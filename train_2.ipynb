{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding JPEG images and decoding/encoding RLE datasets\n",
    "# !pip3 install pylibjpeg==1.4.0\n",
    "# https://github.com/pydicom/pylibjpeg\n",
    "\n",
    "# !pip3 install python-gdcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for kaggle notebook\n",
    "# sys.path = ['../ca_2',] + sys.path\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, ast, cv2, time, pickle, random\n",
    "# import pylibjpeg\n",
    "# import gdcm\n",
    "# import pydicom\n",
    "# pydicom is a pure Python package for working with DICOM files. \n",
    "# -It lets you read, modify and write DICOM data in an easy \"pythonic\" way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# import nibabel as nib\n",
    "# read / write access to some common neuroimaging file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import albumentations # python library for pixel-level augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip3 install torchview\n",
    "# from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "pd.set_option('display.max_colwidth', None) # 500\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "# benchmark mode is good whenever your input sizes for your network do not vary. \n",
    "# This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "#kernel_type = '0920_1bonev2_convnn_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
    "#backbone = 'convnext_nano'\n",
    "\n",
    "image_size = 224\n",
    "n_slice_per_c = 15\n",
    "in_chans = 6\n",
    "\n",
    "# 0.0001\n",
    "init_lr = 18845e-11 # 18845e-9, last good run => 18845e-10 \n",
    "eta_min = 18800e-11 # 18800e-9\n",
    "batch_size = 5 \n",
    "drop_rate = 0. \n",
    "drop_path_rate = 0.\n",
    "drop_rate_last = 0.\n",
    "p_mixup = 0.5 \n",
    "p_rand_order_v1 = 0.5 \n",
    "weight_decay=0 # default: based on optimizer, regularizer like dropout to prevent overfitting.\n",
    "n_accumulate=1 # \n",
    "\n",
    "data_dir = './'\n",
    "use_amp = True\n",
    "num_workers = 11 # 12\n",
    "out_dim = 1\n",
    "\n",
    "n_epochs = 1 # 80\n",
    "\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "model_dir_seg = './kaggle'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/albumentations/augmentations/blur/transforms.py:185: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "# # Albumentations is a computer vision tool that boosts the performance of deep convolutional neural networks.\n",
    "# # Albumentations is a Python library for image augmentation.\n",
    "transforms_train = albumentations.Compose([\n",
    "#     albumentations.Resize(image_size, image_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=0.1, p=0.5),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.5),\n",
    "    \n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),        \n",
    "    \n",
    "    albumentations.CoarseDropout(max_height=int(image_size * 0.5), max_width=int(image_size * 0.5), max_holes=1, p=0.5),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "##     albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Cid</th>\n",
       "      <th>Cid_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14121</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14125</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                StudyInstanceUID  Cid  Cid_label  fold\n",
       "14121  1.2.826.0.1.3680043.18786    3          0     4\n",
       "14122  1.2.826.0.1.3680043.18786    4          0     4\n",
       "14123  1.2.826.0.1.3680043.18786    5          0     4\n",
       "14124  1.2.826.0.1.3680043.18786    6          0     4\n",
       "14125  1.2.826.0.1.3680043.18786    7          1     4"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_dir, 'train_seg.csv'))\n",
    "# df_train =>\n",
    "#             StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
    "# 0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0   \n",
    "# 1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0   \n",
    "# 2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
    "# ...\n",
    "# len(df_train) => 2018\n",
    "\n",
    "df = df_train.sample(16).reset_index(drop=True) if DEBUG else df_train\n",
    "\n",
    "sid = []\n",
    "cs = []\n",
    "label = []\n",
    "fold = []\n",
    "for _, row in df.iterrows():\n",
    "    for i in [1,2,3,4,5,6,7]:\n",
    "        sid.append(row.StudyInstanceUID)\n",
    "        cs.append(i)\n",
    "        label.append(row[f'C{i}'])\n",
    "        fold.append(row.fold)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'StudyInstanceUID': sid,\n",
    "    'Cid': cs,\n",
    "    'Cid_label': label,\n",
    "    'fold': fold\n",
    "})\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Cid</th>\n",
       "      <th>Cid_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  Cid  Cid_label  fold\n",
       "5   1.2.826.0.1.3680043.6200    6          0     0\n",
       "6   1.2.826.0.1.3680043.6200    7          0     0\n",
       "7  1.2.826.0.1.3680043.27262    1          0     0\n",
       "8  1.2.826.0.1.3680043.27262    2          1     0\n",
       "9  1.2.826.0.1.3680043.27262    3          0     0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[5:10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        cid = row.Cid\n",
    "        \n",
    "        images = []\n",
    "            \n",
    "        filepath = os.path.join(data_dir, f'numpy_2/{row.StudyInstanceUID}_{cid}.npy')\n",
    "        images = np.load(filepath)            \n",
    "            # type(image), image.shape => <class 'numpy.ndarray'> (15, 224, 224, 6)\n",
    "\n",
    "        images = np.stack([self.transform(image=images[i])['image'] for i in range(n_slice_per_c)], 0)\n",
    "        \n",
    "        images = images.transpose(0,3,1,2)\n",
    "            # type(image), image.shape => <class 'numpy.ndarray'> (15, 6, 224, 224)        \n",
    "\n",
    "        images = (images / 255.).astype(np.float32) # trim the 'data values' between 0. and 1. \n",
    "            \n",
    "\n",
    "        if self.mode != 'test':\n",
    "            images = torch.tensor(images)#.float()\n",
    "\n",
    "            # images.shape => torch.Size([15, 6, 224, 224])            \n",
    "            labels = torch.tensor([row.Cid_label] * n_slice_per_c).float()\n",
    "                # labels => tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "            # randomly shuffling slices of row of 10% train data.\n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:                \n",
    "                indices = torch.randperm(images.size(0))\n",
    "                # indices => tensor([ 0,  3, 13, 11, 14,  6,  9,  1, 12,  8,  5,  2,  7, 10,  4])           \n",
    "                images = images[indices]\n",
    "                    # images.shape => torch.Size([15, 6, 224, 224])\n",
    "                \n",
    "            return images, labels\n",
    "        else:\n",
    "            return torch.tensor(images)#.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # plt.rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# df_show = df[7:8]\n",
    "# dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = dataset_show[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:23.245545Z",
     "iopub.status.busy": "2022-10-29T08:46:23.245146Z",
     "iopub.status.idle": "2022-10-29T08:46:23.26229Z",
     "shell.execute_reply": "2022-10-29T08:46:23.260005Z",
     "shell.execute_reply.started": "2022-10-29T08:46:23.245506Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        # self.encoder.default_cfg =>\n",
    "        # {'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_s_21ft1k-d7dafa41.pth', \n",
    "        # 'num_classes': 1000, 'input_size': (3, 300, 300), 'pool_size': (10, 10), 'crop_pct': 1.0, 'interpolation': \n",
    "        # 'bicubic', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'first_conv': 'conv_stem', 'classifier': 'classifier', \n",
    "        # 'test_input_size': (3, 384, 384), 'architecture': 'tf_efficientnetv2_s_in21ft1k'}        \n",
    "\n",
    "\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "                # (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
    "                # self.encoder.conv_head => Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)  \n",
    "                # self.encoder.conv_head.out_channels => 1280\n",
    "                \n",
    "                # nn.Identity() => Identity()\n",
    "                # self.encoder.classifier => Linear(in_features=1280, out_features=1, bias=True)  \n",
    "            # replace the last classifier layer with identity layer.\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256), # replaced BatchNorm1d for training with batch_size = 1\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        # x.shape => torch.Size([2, 15, 6, 224, 224])\n",
    "        \n",
    "        bs = x.shape[0]\n",
    "        # Tensor.view(*shape) => Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "            # x.shape => torch.Size([30, 6, 224, 224])\n",
    "        \n",
    "        feat = self.encoder(x)        \n",
    "\n",
    "            # feat.shape => torch.Size([30, 1280])        \n",
    "        feat = feat.view(bs, n_slice_per_c, -1)\n",
    "            # feat.shape => torch.Size([2, 15, 1280])\n",
    "        \n",
    "        feat, _ = self.lstm(feat) # multiple outputs by lstm layer.\n",
    "        \n",
    "        # tensor.contiguous() will create a copy of the tensor, and the element in the copy will be stored in the memory in a contiguous(ordered) way.\n",
    "        # contiguous(ordered) => change the order of data in accordance to indices.\n",
    "        # contiguous() function is usually required when we 'changed the shape of a tensor' and further reshaping (view) it. \n",
    "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        \n",
    "        feat = self.head(feat)\n",
    "        feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "\n",
    "        return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:23.265243Z",
     "iopub.status.busy": "2022-10-29T08:46:23.26406Z",
     "iopub.status.idle": "2022-10-29T08:46:32.738976Z",
     "shell.execute_reply": "2022-10-29T08:46:32.73783Z",
     "shell.execute_reply.started": "2022-10-29T08:46:23.265207Z"
    }
   },
   "outputs": [],
   "source": [
    "# m = TimmModel(backbone)\n",
    "# m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape\n",
    "#     # m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape => torch.Size([2, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(m, input_data = torch.rand(1, 15, 6, 224, 224), expand_nested=True, save_graph=True).visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.741112Z",
     "iopub.status.busy": "2022-10-29T08:46:32.740646Z",
     "iopub.status.idle": "2022-10-29T08:46:32.74936Z",
     "shell.execute_reply": "2022-10-29T08:46:32.747958Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.741073Z"
    }
   },
   "outputs": [],
   "source": [
    "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "\n",
    "def criterion(logits, targets, activated=False):\n",
    "    if activated:\n",
    "        losses = nn.BCELoss(reduction='none')(logits.view(-1), targets.view(-1))\n",
    "    else:\n",
    "        losses = bce(logits.view(-1), targets.view(-1))\n",
    "    losses[targets.view(-1) > 0] *= 2.\n",
    "    norm = torch.ones(logits.view(-1).shape[0]).to(device)\n",
    "    norm[targets.view(-1) > 0] *= 2\n",
    "    return losses.sum() / norm.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Valid func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.75212Z",
     "iopub.status.busy": "2022-10-29T08:46:32.751519Z",
     "iopub.status.idle": "2022-10-29T08:46:32.766761Z",
     "shell.execute_reply": "2022-10-29T08:46:32.765711Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.752079Z"
    }
   },
   "outputs": [],
   "source": [
    "# mixup explained in train_1.ipynb\n",
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader_train)\n",
    "    t=0    \n",
    "    for images, targets in bar:\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < p_mixup:\n",
    "            do_mixup = True\n",
    "            images, targets, targets_mix, lam = mixup(images, targets)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(logits, targets_mix)\n",
    "                loss = loss * lam  + loss11 * (1 - lam)\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (t + 1) % n_accumulate == 0:            \n",
    "            scaler.step(optimizer)            \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.        \n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            # optimizer's assigned params; parameters which are to be optimized by optimizer.\n",
    "        \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "            \n",
    "            # to reset the gradients of model parameters.             \n",
    "            optimizer.zero_grad()   \n",
    "            t=-1\n",
    "        t+=1        \n",
    "\n",
    "        bar.set_description(f'smooth loss:{np.mean(train_loss[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    gts = []\n",
    "    outputs = []\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            gts.append(targets.cpu())\n",
    "            outputs.append(logits.cpu())\n",
    "            valid_loss.append(loss.item())\n",
    "            \n",
    "#             bar.set_description(f'smooth loss:{np.mean(valid_loss[-30:]):.4f}')\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    gts = torch.cat(gts)\n",
    "    valid_loss = criterion(outputs, gts).item()\n",
    "\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = TimmModel(backbone)\n",
    "# plt.rcParams['figure.figsize'] = 20, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.770948Z",
     "iopub.status.busy": "2022-10-29T08:46:32.770484Z",
     "iopub.status.idle": "2022-10-29T08:46:33.001268Z",
     "shell.execute_reply": "2022-10-29T08:46:33.000206Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.77091Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer = optim.AdamW(m.parameters(), lr=15e-7)\n",
    "# scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 18, eta_min = 11e-9)\n",
    "# # scheduler_cosine = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=0.33, total_iters=22)\n",
    "\n",
    "# lrs = []\n",
    "# for epoch in range(1, 18+1):\n",
    "#     scheduler_cosine.step(epoch-1)\n",
    "#     lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "# plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_debug = df.copy()\n",
    "# df = df[1000:]\n",
    "# df = df_debug[1006:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:33.003917Z",
     "iopub.status.busy": "2022-10-29T08:46:33.003238Z",
     "iopub.status.idle": "2022-10-29T08:46:33.01973Z",
     "shell.execute_reply": "2022-10-29T08:46:33.018392Z",
     "shell.execute_reply.started": "2022-10-29T08:46:33.003873Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModel(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    #if not first run, load previous model\n",
    "    fold_l = 0\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold_l}_last.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)    \n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr, weight_decay=weight_decay)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=init_lr, weight_decay=weight_decay)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    metric_best = 0.25\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "#     print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "\n",
    "#         print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss = valid_func(model, loader_valid)\n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train_loss: {train_loss:.5f}, valid_loss: {valid_loss:.5f}, metric(valid_loss): {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "#         if metric < metric_best:#abs(train_loss-valid_loss) <= 0.01:\n",
    "#             print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "#                 torch.save(model.state_dict(), model_file)\n",
    "#                 metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:# and abs(train_loss-valid_loss) <= 0.005\n",
    "            torch.save(model.state_dict(), model_file.replace('_best', '_last'))\n",
    "#             torch.save(\n",
    "#                 {\n",
    "#                     'epoch': epoch,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "#                     'score_best': metric_best,\n",
    "#                 },\n",
    "#                 model_file.replace('_best', '_last')\n",
    "#             )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:33.021919Z",
     "iopub.status.busy": "2022-10-29T08:46:33.021481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.1959: 100%|███████████████████| 2259/2259 [17:47<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████| 566/566 [02:11<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 10:17:32 2023 Fold 1, Epoch 1, lr: 0.0000002, train_loss: 0.23632, valid_loss: 0.15263, metric(valid_loss): 0.152631.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2638: 100%|███████████████████| 2261/2261 [17:47<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████| 565/565 [02:11<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 10:37:33 2023 Fold 2, Epoch 1, lr: 0.0000002, train_loss: 0.25080, valid_loss: 0.15264, metric(valid_loss): 0.152636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2548: 100%|███████████████████| 2259/2259 [17:48<00:00,  2.11it/s]\n",
      "100%|█████████████████████████████████████████| 566/566 [02:12<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 10:57:34 2023 Fold 3, Epoch 1, lr: 0.0000002, train_loss: 0.25017, valid_loss: 0.19627, metric(valid_loss): 0.196266.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2810: 100%|███████████████████| 2261/2261 [17:49<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████| 565/565 [02:11<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 11:17:36 2023 Fold 4, Epoch 1, lr: 0.0000002, train_loss: 0.25400, valid_loss: 0.18295, metric(valid_loss): 0.182947.\n"
     ]
    }
   ],
   "source": [
    "#run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_loss: 0.21034, valid_loss: 0.14995, fold0 last both kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
