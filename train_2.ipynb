{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding JPEG images and decoding/encoding RLE datasets\n",
    "# !pip3 install pylibjpeg==1.4.0\n",
    "# https://github.com/pydicom/pylibjpeg\n",
    "\n",
    "# !pip3 install python-gdcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for kaggle notebook\n",
    "# sys.path = ['../ca_2',] + sys.path\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, ast, cv2, time, pickle, random\n",
    "# import pylibjpeg\n",
    "# import gdcm\n",
    "# import pydicom\n",
    "# pydicom is a pure Python package for working with DICOM files. \n",
    "# -It lets you read, modify and write DICOM data in an easy \"pythonic\" way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# import nibabel as nib\n",
    "# read / write access to some common neuroimaging file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import albumentations # python library for pixel-level augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip3 install torchview\n",
    "# from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "pd.set_option('display.max_colwidth', None) # 500\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# benchmark mode is good whenever your input sizes for your network do not vary. \n",
    "# This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
    "\n",
    "image_size = 224\n",
    "n_slice_per_c = 15\n",
    "in_chans = 6\n",
    "\n",
    "init_lr = 23e-5 # 23e-5 (for first run)\n",
    "eta_min = 13e-5 # 23e-6 (for first run)\n",
    "batch_size = 5 # 8\n",
    "drop_rate = 0.\n",
    "drop_rate_last = 0.3 # 0.3\n",
    "drop_path_rate = 0.\n",
    "p_mixup = 0.5\n",
    "p_rand_order_v1 = 0.2\n",
    "\n",
    "data_dir = './'\n",
    "use_amp = True\n",
    "num_workers = 12 # 4\n",
    "out_dim = 1\n",
    "\n",
    "n_epochs = 30 # 75\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "model_dir_seg = './kaggle'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/albumentations/augmentations/blur/transforms.py:185: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "# Albumentations is a computer vision tool that boosts the performance of deep convolutional neural networks.\n",
    "# Albumentations is a Python library for image augmentation.\n",
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.CoarseDropout(max_height=int(image_size * 0.5), max_width=int(image_size * 0.5), max_holes=1, p=0.5),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Cid</th>\n",
       "      <th>Cid_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14121</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14125</th>\n",
       "      <td>1.2.826.0.1.3680043.18786</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                StudyInstanceUID  Cid  Cid_label  fold\n",
       "14121  1.2.826.0.1.3680043.18786    3          0     4\n",
       "14122  1.2.826.0.1.3680043.18786    4          0     4\n",
       "14123  1.2.826.0.1.3680043.18786    5          0     4\n",
       "14124  1.2.826.0.1.3680043.18786    6          0     4\n",
       "14125  1.2.826.0.1.3680043.18786    7          1     4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(data_dir, 'train_seg.csv'))\n",
    "# df_train =>\n",
    "#             StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
    "# 0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0   \n",
    "# 1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0   \n",
    "# 2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
    "# ...\n",
    "# len(df_train) => 2018\n",
    "\n",
    "df = df_train.sample(16).reset_index(drop=True) if DEBUG else df_train\n",
    "\n",
    "sid = []\n",
    "cs = []\n",
    "label = []\n",
    "fold = []\n",
    "for _, row in df.iterrows():\n",
    "    for i in [1,2,3,4,5,6,7]:\n",
    "        sid.append(row.StudyInstanceUID)\n",
    "        cs.append(i)\n",
    "        label.append(row[f'C{i}'])\n",
    "        fold.append(row.fold)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'StudyInstanceUID': sid,\n",
    "    'Cid': cs,\n",
    "    'Cid_label': label,\n",
    "    'fold': fold\n",
    "})\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Cid</th>\n",
       "      <th>Cid_label</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  Cid  Cid_label  fold\n",
       "5   1.2.826.0.1.3680043.6200    6          0     0\n",
       "6   1.2.826.0.1.3680043.6200    7          0     0\n",
       "7  1.2.826.0.1.3680043.27262    1          0     0\n",
       "8  1.2.826.0.1.3680043.27262    2          1     0\n",
       "9  1.2.826.0.1.3680043.27262    3          0     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[5:10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        cid = row.Cid\n",
    "        \n",
    "        images = []\n",
    "            \n",
    "        filepath = os.path.join(data_dir, f'numpy_1/{row.StudyInstanceUID}_{cid}.npy')\n",
    "        images = np.load(filepath)            \n",
    "            # type(image), image.shape => <class 'numpy.ndarray'> (15, 224, 224, 6)\n",
    "\n",
    "        images = np.stack([self.transform(image=images[i])['image'] for i in range(n_slice_per_c)], 0)\n",
    "        \n",
    "        images = images.transpose(0,3,1,2)\n",
    "            # type(image), image.shape => <class 'numpy.ndarray'> (15, 6, 224, 224)        \n",
    "\n",
    "        images = images / 255. # trim the 'data values' between 0. and 1. \n",
    "            # prior to 255. divide, convert data to float\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            images = torch.tensor(images).float()  \n",
    "\n",
    "            # images.shape => torch.Size([15, 6, 224, 224])            \n",
    "            labels = torch.tensor([row.Cid_label] * n_slice_per_c).float()\n",
    "                # labels => tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "            # randomly shuffling slices of row of 10% train data.\n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:                \n",
    "                indices = torch.randperm(images.size(0))\n",
    "                # indices => tensor([ 0,  3, 13, 11, 14,  6,  9,  1, 12,  8,  5,  2,  7, 10,  4])           \n",
    "                images = images[indices]\n",
    "                    # images.shape => torch.Size([15, 6, 224, 224])\n",
    "                \n",
    "            return images, labels\n",
    "        else:\n",
    "            return torch.tensor(images).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # plt.rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "# df_show = df[7:8]\n",
    "# dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_show[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:23.245545Z",
     "iopub.status.busy": "2022-10-29T08:46:23.245146Z",
     "iopub.status.idle": "2022-10-29T08:46:23.26229Z",
     "shell.execute_reply": "2022-10-29T08:46:23.260005Z",
     "shell.execute_reply.started": "2022-10-29T08:46:23.245506Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        # self.encoder.default_cfg =>\n",
    "        # {'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-effv2-weights/tf_efficientnetv2_s_21ft1k-d7dafa41.pth', \n",
    "        # 'num_classes': 1000, 'input_size': (3, 300, 300), 'pool_size': (10, 10), 'crop_pct': 1.0, 'interpolation': \n",
    "        # 'bicubic', 'mean': (0.5, 0.5, 0.5), 'std': (0.5, 0.5, 0.5), 'first_conv': 'conv_stem', 'classifier': 'classifier', \n",
    "        # 'test_input_size': (3, 384, 384), 'architecture': 'tf_efficientnetv2_s_in21ft1k'}        \n",
    "\n",
    "\n",
    "        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "                # (conv_head): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False) \n",
    "                # self.encoder.conv_head => Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)  \n",
    "                # self.encoder.conv_head.out_channels => 1280\n",
    "                \n",
    "                # nn.Identity() => Identity()\n",
    "                # self.encoder.classifier => Linear(in_features=1280, out_features=1, bias=True)  \n",
    "            # replace the last classifier layer with identity layer.\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256), # replaced BatchNorm1d for training with batch_size = 1\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        # x.shape => torch.Size([2, 15, 6, 224, 224])\n",
    "        \n",
    "        bs = x.shape[0]\n",
    "        # Tensor.view(*shape) => Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)\n",
    "            # x.shape => torch.Size([30, 6, 224, 224])\n",
    "        \n",
    "        feat = self.encoder(x)        \n",
    "\n",
    "            # feat.shape => torch.Size([30, 1280])        \n",
    "        feat = feat.view(bs, n_slice_per_c, -1)\n",
    "            # feat.shape => torch.Size([2, 15, 1280])\n",
    "        \n",
    "        feat, _ = self.lstm(feat) # multiple outputs by lstm layer.\n",
    "        \n",
    "        # tensor.contiguous() will create a copy of the tensor, and the element in the copy will be stored in the memory in a contiguous(ordered) way.\n",
    "        # contiguous(ordered) => change the order of data in accordance to indices.\n",
    "        # contiguous() function is usually required when we 'changed the shape of a tensor' and further reshaping (view) it. \n",
    "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)\n",
    "        \n",
    "        feat = self.head(feat)\n",
    "        feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "\n",
    "        return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:23.265243Z",
     "iopub.status.busy": "2022-10-29T08:46:23.26406Z",
     "iopub.status.idle": "2022-10-29T08:46:32.738976Z",
     "shell.execute_reply": "2022-10-29T08:46:32.73783Z",
     "shell.execute_reply.started": "2022-10-29T08:46:23.265207Z"
    }
   },
   "outputs": [],
   "source": [
    "# m = TimmModel(backbone)\n",
    "# m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape\n",
    "#     # m(torch.rand(2, n_slice_per_c, in_chans, image_size, image_size)).shape => torch.Size([2, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(m, input_data = torch.rand(1, 15, 6, 224, 224), expand_nested=True, save_graph=True).visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.741112Z",
     "iopub.status.busy": "2022-10-29T08:46:32.740646Z",
     "iopub.status.idle": "2022-10-29T08:46:32.74936Z",
     "shell.execute_reply": "2022-10-29T08:46:32.747958Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.741073Z"
    }
   },
   "outputs": [],
   "source": [
    "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "\n",
    "def criterion(logits, targets, activated=False):\n",
    "    if activated:\n",
    "        losses = nn.BCELoss(reduction='none')(logits.view(-1), targets.view(-1))\n",
    "    else:\n",
    "        losses = bce(logits.view(-1), targets.view(-1))\n",
    "    losses[targets.view(-1) > 0] *= 2.\n",
    "    norm = torch.ones(logits.view(-1).shape[0]).to(device)\n",
    "    norm[targets.view(-1) > 0] *= 2\n",
    "    return losses.sum() / norm.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Valid func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.75212Z",
     "iopub.status.busy": "2022-10-29T08:46:32.751519Z",
     "iopub.status.idle": "2022-10-29T08:46:32.766761Z",
     "shell.execute_reply": "2022-10-29T08:46:32.765711Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.752079Z"
    }
   },
   "outputs": [],
   "source": [
    "# mixup explained in train_1.ipynb\n",
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, targets in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < p_mixup:\n",
    "            do_mixup = True\n",
    "            images, targets, targets_mix, lam = mixup(images, targets)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(logits, targets_mix)\n",
    "                loss = loss * lam  + loss11 * (1 - lam)\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "#         bar.set_description(f'smooth loss:{np.mean(train_loss[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    gts = []\n",
    "    outputs = []\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, targets)\n",
    "            \n",
    "            gts.append(targets.cpu())\n",
    "            outputs.append(logits.cpu())\n",
    "            valid_loss.append(loss.item())\n",
    "            \n",
    "#             bar.set_description(f'smooth loss:{np.mean(valid_loss[-30:]):.4f}')\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    gts = torch.cat(gts)\n",
    "    valid_loss = criterion(outputs, gts).item()\n",
    "\n",
    "    return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:32.770948Z",
     "iopub.status.busy": "2022-10-29T08:46:32.770484Z",
     "iopub.status.idle": "2022-10-29T08:46:33.001268Z",
     "shell.execute_reply": "2022-10-29T08:46:33.000206Z",
     "shell.execute_reply.started": "2022-10-29T08:46:32.77091Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.rcParams['figure.figsize'] = 20, 2\n",
    "# optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "# scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min = 23e-8)\n",
    "\n",
    "# lrs = []\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "#     scheduler_cosine.step(epoch-1)\n",
    "#     lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "# plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_debug = df.copy()\n",
    "# df = df[1000:]\n",
    "# df = df_debug[1006:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:33.003917Z",
     "iopub.status.busy": "2022-10-29T08:46:33.003238Z",
     "iopub.status.idle": "2022-10-29T08:46:33.01973Z",
     "shell.execute_reply": "2022-10-29T08:46:33.018392Z",
     "shell.execute_reply.started": "2022-10-29T08:46:33.003873Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModel(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # if not first run, load previous model\n",
    "    fold_l = 0\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold_l}_best.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)    \n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "    metric_best = np.inf\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "#     print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "\n",
    "#         print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss = valid_func(model, loader_valid)\n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train_loss: {train_loss:.5f}, valid_loss: {valid_loss:.5f}, metric(valid_loss): {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric < metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "#         # Save Last\n",
    "#         if not DEBUG:\n",
    "#             torch.save(\n",
    "#                 {\n",
    "#                     'epoch': epoch,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "#                     'score_best': metric_best,\n",
    "#                 },\n",
    "#                 model_file.replace('_best', '_last')\n",
    "#             )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:46:33.021919Z",
     "iopub.status.busy": "2022-10-29T08:46:33.021481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3912: 100%|███████████████████| 2261/2261 [17:35<00:00,  2.14it/s]\n",
      "smooth loss:0.6242: 100%|█████████████████████| 565/565 [02:18<00:00,  4.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 24 23:04:54 2023 Fold 2, Epoch 1, lr: 0.0002300, train_loss: 0.33754, valid_loss: 0.29303, metric(valid_loss): 0.293033.\n",
      "metric_best (inf --> 0.293033). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2978: 100%|███████████████████| 2261/2261 [17:23<00:00,  2.17it/s]\n",
      "smooth loss:0.6294: 100%|█████████████████████| 565/565 [02:15<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 24 23:24:34 2023 Fold 2, Epoch 2, lr: 0.0002297, train_loss: 0.33458, valid_loss: 0.29124, metric(valid_loss): 0.291239.\n",
      "metric_best (0.293033 --> 0.291239). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3610: 100%|███████████████████| 2261/2261 [17:22<00:00,  2.17it/s]\n",
      "smooth loss:0.7273: 100%|█████████████████████| 565/565 [02:15<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 24 23:44:12 2023 Fold 2, Epoch 3, lr: 0.0002289, train_loss: 0.34282, valid_loss: 0.29550, metric(valid_loss): 0.295497.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3449: 100%|███████████████████| 2261/2261 [17:24<00:00,  2.17it/s]\n",
      "smooth loss:0.8650: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 00:03:52 2023 Fold 2, Epoch 4, lr: 0.0002276, train_loss: 0.34012, valid_loss: 0.32518, metric(valid_loss): 0.325180.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2869: 100%|███████████████████| 2261/2261 [17:23<00:00,  2.17it/s]\n",
      "smooth loss:0.8293: 100%|█████████████████████| 565/565 [02:15<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 00:23:32 2023 Fold 2, Epoch 5, lr: 0.0002257, train_loss: 0.34405, valid_loss: 0.31270, metric(valid_loss): 0.312698.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3439: 100%|███████████████████| 2261/2261 [17:25<00:00,  2.16it/s]\n",
      "smooth loss:0.7096: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 00:43:13 2023 Fold 2, Epoch 6, lr: 0.0002233, train_loss: 0.33175, valid_loss: 0.29336, metric(valid_loss): 0.293360.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.4644: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7892: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 01:02:55 2023 Fold 2, Epoch 7, lr: 0.0002205, train_loss: 0.34313, valid_loss: 0.31755, metric(valid_loss): 0.317551.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.4019: 100%|███████████████████| 2261/2261 [17:24<00:00,  2.16it/s]\n",
      "smooth loss:0.7275: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 01:22:35 2023 Fold 2, Epoch 8, lr: 0.0002172, train_loss: 0.32939, valid_loss: 0.30997, metric(valid_loss): 0.309972.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3345: 100%|███████████████████| 2261/2261 [17:25<00:00,  2.16it/s]\n",
      "smooth loss:0.8049: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 01:42:16 2023 Fold 2, Epoch 9, lr: 0.0002135, train_loss: 0.34071, valid_loss: 0.31467, metric(valid_loss): 0.314669.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3675: 100%|███████████████████| 2261/2261 [17:24<00:00,  2.16it/s]\n",
      "smooth loss:0.6635: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 02:01:57 2023 Fold 2, Epoch 10, lr: 0.0002094, train_loss: 0.33247, valid_loss: 0.30406, metric(valid_loss): 0.304059.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3484: 100%|███████████████████| 2261/2261 [17:27<00:00,  2.16it/s]\n",
      "smooth loss:0.7143: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 02:21:40 2023 Fold 2, Epoch 11, lr: 0.0002050, train_loss: 0.33177, valid_loss: 0.29781, metric(valid_loss): 0.297811.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2847: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7270: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 02:41:23 2023 Fold 2, Epoch 12, lr: 0.0002003, train_loss: 0.33150, valid_loss: 0.30675, metric(valid_loss): 0.306746.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2527: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.8415: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 03:01:05 2023 Fold 2, Epoch 13, lr: 0.0001955, train_loss: 0.32637, valid_loss: 0.31917, metric(valid_loss): 0.319166.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3675: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7513: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 03:20:48 2023 Fold 2, Epoch 14, lr: 0.0001904, train_loss: 0.32891, valid_loss: 0.30972, metric(valid_loss): 0.309723.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3568: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7233: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 03:40:30 2023 Fold 2, Epoch 15, lr: 0.0001852, train_loss: 0.32498, valid_loss: 0.29104, metric(valid_loss): 0.291039.\n",
      "metric_best (0.291239 --> 0.291039). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2380: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7391: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 04:00:13 2023 Fold 2, Epoch 16, lr: 0.0001800, train_loss: 0.32547, valid_loss: 0.28811, metric(valid_loss): 0.288115.\n",
      "metric_best (0.291039 --> 0.288115). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3649: 100%|███████████████████| 2261/2261 [17:27<00:00,  2.16it/s]\n",
      "smooth loss:0.6701: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 04:19:57 2023 Fold 2, Epoch 17, lr: 0.0001748, train_loss: 0.32426, valid_loss: 0.29868, metric(valid_loss): 0.298683.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3510: 100%|███████████████████| 2261/2261 [17:27<00:00,  2.16it/s]\n",
      "smooth loss:0.7659: 100%|█████████████████████| 565/565 [02:15<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 04:39:40 2023 Fold 2, Epoch 18, lr: 0.0001696, train_loss: 0.32302, valid_loss: 0.28074, metric(valid_loss): 0.280741.\n",
      "metric_best (0.288115 --> 0.280741). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2405: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7121: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 04:59:23 2023 Fold 2, Epoch 19, lr: 0.0001645, train_loss: 0.32478, valid_loss: 0.29358, metric(valid_loss): 0.293577.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3868: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7166: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 05:19:06 2023 Fold 2, Epoch 20, lr: 0.0001597, train_loss: 0.32158, valid_loss: 0.28810, metric(valid_loss): 0.288097.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3602: 100%|███████████████████| 2261/2261 [17:25<00:00,  2.16it/s]\n",
      "smooth loss:0.8026: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 05:38:47 2023 Fold 2, Epoch 21, lr: 0.0001550, train_loss: 0.32051, valid_loss: 0.31761, metric(valid_loss): 0.317606.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2993: 100%|███████████████████| 2261/2261 [17:25<00:00,  2.16it/s]\n",
      "smooth loss:0.6961: 100%|█████████████████████| 565/565 [02:15<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 05:58:28 2023 Fold 2, Epoch 22, lr: 0.0001506, train_loss: 0.31717, valid_loss: 0.29145, metric(valid_loss): 0.291452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2774: 100%|███████████████████| 2261/2261 [17:25<00:00,  2.16it/s]\n",
      "smooth loss:0.7439: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 06:18:10 2023 Fold 2, Epoch 23, lr: 0.0001465, train_loss: 0.31497, valid_loss: 0.28436, metric(valid_loss): 0.284357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3590: 100%|███████████████████| 2261/2261 [17:26<00:00,  2.16it/s]\n",
      "smooth loss:0.7522: 100%|█████████████████████| 565/565 [02:16<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 06:37:54 2023 Fold 2, Epoch 24, lr: 0.0001428, train_loss: 0.31355, valid_loss: 0.28728, metric(valid_loss): 0.287283.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.1682: 100%|███████████████████| 2261/2261 [17:31<00:00,  2.15it/s]\n",
      "smooth loss:0.7386: 100%|█████████████████████| 565/565 [02:26<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 06:57:52 2023 Fold 2, Epoch 25, lr: 0.0001395, train_loss: 0.31377, valid_loss: 0.28069, metric(valid_loss): 0.280693.\n",
      "metric_best (0.280741 --> 0.280693). Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2703: 100%|███████████████████| 2261/2261 [18:17<00:00,  2.06it/s]\n",
      "smooth loss:0.7490: 100%|█████████████████████| 565/565 [02:27<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 07:18:37 2023 Fold 2, Epoch 26, lr: 0.0001367, train_loss: 0.32133, valid_loss: 0.28505, metric(valid_loss): 0.285054.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.3352: 100%|███████████████████| 2261/2261 [18:17<00:00,  2.06it/s]\n",
      "smooth loss:0.7621: 100%|█████████████████████| 565/565 [02:24<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 25 07:39:18 2023 Fold 2, Epoch 27, lr: 0.0001343, train_loss: 0.30631, valid_loss: 0.28146, metric(valid_loss): 0.281457.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smooth loss:0.2460:   4%|▊                    | 82/2261 [00:43<19:02,  1.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6601/501955175.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # run(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# run(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# run(3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6601/3155832608.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m#         print(time.ctime(), 'Epoch:', epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6601/747658572.py\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(model, loader_train, optimizer, scaler)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    174\u001b[0m                   \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                   \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                   capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    230\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcapturable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # run(0)\n",
    "# run(1)\n",
    "run(2)\n",
    "run(4)\n",
    "# run(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
