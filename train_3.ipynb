{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding JPEG images and decoding/encoding RLE datasets\n",
    "# !pip3 install pylibjpeg==1.4.0\n",
    "# https://github.com/pydicom/pylibjpeg\n",
    "\n",
    "# !pip3 install python-gdcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suitable for kaggle notebook\n",
    "# sys.path = ['../ca_2',] + sys.path\n",
    "# print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, ast, cv2, time, pickle, random\n",
    "# import pylibjpeg\n",
    "# import gdcm\n",
    "# import pydicom\n",
    "# pydicom is a pure Python package for working with DICOM files. \n",
    "# -It lets you read, modify and write DICOM data in an easy \"pythonic\" way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# import nibabel as nib\n",
    "# read / write access to some common neuroimaging file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import albumentations # python library for pixel-level augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "# import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip3 install torchview\n",
    "# from torchview import draw_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "pd.set_option('display.max_colwidth', None) # 500\n",
    "pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# benchmark mode is good whenever your input sizes for your network do not vary. \n",
    "# This flag allows you to enable the inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware.\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T09:08:50.228479Z",
     "iopub.status.busy": "2022-10-29T09:08:50.228099Z",
     "iopub.status.idle": "2022-10-29T09:08:50.237679Z",
     "shell.execute_reply": "2022-10-29T09:08:50.235921Z",
     "shell.execute_reply.started": "2022-10-29T09:08:50.228447Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_type = '0920_2d_lstmv22headv2_convnn_224_15_6ch_8flip_augv2_drl3_rov1p2_rov3p2_bs4_lr6e5_eta6e6_lw151_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "backbone = 'convnext_nano'\n",
    "\n",
    "image_size = 224\n",
    "n_slice_per_c = 15\n",
    "in_chans = 6\n",
    "\n",
    "init_lr = 19e-8 # 19e-5, \n",
    "eta_min = 11e-8 # 11e-6\n",
    "lw = [15, 1]\n",
    "batch_size = 1\n",
    "drop_rate = 0. # 0.\n",
    "drop_path_rate = 0.\n",
    "drop_rate_last = 0.3 # 0.3\n",
    "p_mixup = 0.5\n",
    "p_rand_order = 0.2\n",
    "p_rand_order_v1 = 0.2\n",
    "\n",
    "data_dir = './numpy_1/'\n",
    "use_amp = True\n",
    "num_workers = 12 # 12\n",
    "out_dim = 1\n",
    "\n",
    "n_epochs = 25\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "model_dir_seg = './kaggle'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T09:08:51.019330Z",
     "iopub.status.busy": "2022-10-29T09:08:51.018970Z",
     "iopub.status.idle": "2022-10-29T09:08:51.028636Z",
     "shell.execute_reply": "2022-10-29T09:08:51.027512Z",
     "shell.execute_reply.started": "2022-10-29T09:08:51.019300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/na/miniconda3/envs/base_2/lib/python3.7/site-packages/albumentations/augmentations/blur/transforms.py:185: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
      "  \"blur_limit and sigma_limit minimum value can not be both equal to 0. \"\n"
     ]
    }
   ],
   "source": [
    "# Albumentations is a computer vision tool that boosts the performance of deep convolutional neural networks.\n",
    "# Albumentations is a Python library for image augmentation.\n",
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightnessContrast(brightness_limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.CoarseDropout(max_height=int(image_size * 0.5), max_width=int(image_size * 0.5), max_holes=1, p=0.5),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T09:08:51.859289Z",
     "iopub.status.busy": "2022-10-29T09:08:51.858480Z",
     "iopub.status.idle": "2022-10-29T09:08:51.886459Z",
     "shell.execute_reply": "2022-10-29T09:08:51.885393Z",
     "shell.execute_reply.started": "2022-10-29T09:08:51.859244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>mask_file</th>\n",
       "      <th>image_folder</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>d</th>\n",
       "      <th>t</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.6200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.6200</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>243</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.27262</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.27262</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.21561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.21561</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>385</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.12351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.12351</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>501</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.1363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/segmentations/1.2.826.0.1.3680043.1363.nii</td>\n",
       "      <td>/data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.1363</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>199</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  patient_overall  C1  C2  C3  C4  C5  C6  C7  \\\n",
       "0   1.2.826.0.1.3680043.6200                1   1   1   0   0   0   0   0   \n",
       "1  1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0   \n",
       "2  1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0   \n",
       "3  1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0   \n",
       "4   1.2.826.0.1.3680043.1363                1   0   0   0   0   1   0   0   \n",
       "\n",
       "                                                                                      mask_file  \\\n",
       "0                                                                                           NaN   \n",
       "1                                                                                           NaN   \n",
       "2                                                                                           NaN   \n",
       "3                                                                                           NaN   \n",
       "4  /data/rsna-2022-cervical-spine-fracture-detection/segmentations/1.2.826.0.1.3680043.1363.nii   \n",
       "\n",
       "                                                                               image_folder  \\\n",
       "0   /data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.6200   \n",
       "1  /data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.27262   \n",
       "2  /data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.21561   \n",
       "3  /data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.12351   \n",
       "4   /data/rsna-2022-cervical-spine-fracture-detection/train_images/1.2.826.0.1.3680043.1363   \n",
       "\n",
       "     w    h    d      t  fold  \n",
       "0  512  512  243  1.000     0  \n",
       "1  512  512  406  0.500     0  \n",
       "2  512  512  385  0.625     0  \n",
       "3  512  512  501  0.600     0  \n",
       "4  512  512  199  1.000     0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_seg.csv')\n",
    "df = df.sample(16).reset_index(drop=True) if DEBUG else df\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T09:08:52.664349Z",
     "iopub.status.busy": "2022-10-29T09:08:52.663996Z",
     "iopub.status.idle": "2022-10-29T09:08:52.675444Z",
     "shell.execute_reply": "2022-10-29T09:08:52.674271Z",
     "shell.execute_reply.started": "2022-10-29T09:08:52.664319Z"
    }
   },
   "outputs": [],
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        images_lst = []\n",
    "        \n",
    "        tmp = list(range(7))\n",
    "        ### random order v3\n",
    "        if self.mode == 'train' and random.random() < p_rand_order:\n",
    "            random.shuffle(tmp)\n",
    "        ###\n",
    "        for cid in (tmp):                \n",
    "            filepath = os.path.join(data_dir, f'numpy_1/{row.StudyInstanceUID}_{cid+1}.npy')\n",
    "            images = np.load(filepath)            \n",
    "                # type(image), image.shape => <class 'numpy.ndarray'> (15, 224, 224, 6)\n",
    "\n",
    "            images = np.stack([self.transform(image=images[i])['image'] for i in range(n_slice_per_c)], 0)\n",
    "\n",
    "            images = images.transpose(0,3,1,2)\n",
    "                # type(image), image.shape => <class 'numpy.ndarray'> (15, 6, 224, 224)        \n",
    "\n",
    "            images = images / 255. # trim the 'data values' between 0. and 1. \n",
    "                # prior to 255. divide, convert data to float       \n",
    "            images_lst.append(images)                \n",
    "            \n",
    "        images_lst = np.stack(images_lst, 0)#.astype(np.float32)\n",
    "\n",
    "        images_lst = images_lst.reshape((105,6,224,224))\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            labels = []\n",
    "            # tmp => [0, 1, 2, 3, 4, 5, 6]\n",
    "            for i in row[[f'C{x+1}' for x in tmp]].tolist():\n",
    "                labels += [i] * n_slice_per_c\n",
    "                \n",
    "            # labels => [1, 1, 1, 1, 1, 1, 1, 1, .........., 0, 0, 0, 0, 0, 0, 0, 0] => 105 items\n",
    "\n",
    "            images = torch.tensor(images_lst).float()\n",
    "            labels = torch.tensor(labels).float()\n",
    "            \n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:\n",
    "                indices = torch.randperm(images.size(0))\n",
    "                images = images_lst[indices]\n",
    "                labels = labels[indices]\n",
    "\n",
    "            return images, labels\n",
    "        else:\n",
    "            return torch.tensor(images).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_show = df[0:1]\n",
    "# dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa, bb = dataset_show[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T09:09:24.701871Z",
     "iopub.status.busy": "2022-10-29T09:09:24.700750Z",
     "iopub.status.idle": "2022-10-29T09:09:24.715451Z",
     "shell.execute_reply": "2022-10-29T09:09:24.714120Z",
     "shell.execute_reply.started": "2022-10-29T09:09:24.701808Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimmModelType2(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModelType2, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256), # replaced BatchNorm1d for training with batch_size = 1\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256), # replaced BatchNorm1d for training with batch_size = 1\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):  # (bs, nc*7, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "\n",
    "        x = x.view(bs * n_slice_per_c * 7, in_chans, image_size, image_size)\n",
    "\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c * 7, -1)\n",
    "        feat1, _ = self.lstm(feat)\n",
    "        feat1 = feat1.contiguous().view(bs * n_slice_per_c * 7, 512)\n",
    "        feat2, _ = self.lstm2(feat)\n",
    "\n",
    "        return self.head(feat1), self.head2(feat2[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = TimmModelType2(backbone)\n",
    "# n_sequence = 7 * n_slice_per_c\n",
    "# m(torch.rand(2, n_sequence, in_chans, image_size, image_size)).shape\n",
    "# #     m(torch.rand(2, n_sequence, in_chans, image_size, image_size)).shape => torch.Size([2, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_graph(m, input_data = torch.rand(1, 3, 128,128,128), expand_nested=True, save_graph=True).visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "\n",
    "def criterion(logits, targets, activated=False):\n",
    "    if activated:\n",
    "        losses = nn.BCELoss(reduction='none')(logits.view(-1), targets.view(-1))\n",
    "            # .view(-1) => return a single dimension tensor.\n",
    "            # .view() => Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "    else:\n",
    "        losses = bce(logits.view(-1), targets.view(-1))\n",
    "    losses[targets.view(-1) > 0] *= 2.\n",
    "         # losses[targets.view(-1) > 0] => keeping those indices values from losses, where the targets are '> 0'.\n",
    "         # losses[targets.view(-1) > 0] *= 2. =>   losses[targets.view(-1) > 0] = losses[targets.view(-1) > 0] * 2.\n",
    "    norm = torch.ones(logits.view(-1).shape[0]).to(device)\n",
    "    norm[targets.view(-1) > 0] *= 2\n",
    "    return losses.sum() / norm.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Valid func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:11:53.858498Z",
     "iopub.status.busy": "2022-10-29T08:11:53.858143Z",
     "iopub.status.idle": "2022-10-29T08:11:53.87108Z",
     "shell.execute_reply": "2022-10-29T08:11:53.869966Z",
     "shell.execute_reply.started": "2022-10-29T08:11:53.858468Z"
    }
   },
   "outputs": [],
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_loss1 = []\n",
    "    train_loss2 = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, targets in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < p_mixup:\n",
    "            do_mixup = True\n",
    "            images, targets, targets_mix, lam = mixup(images, targets)\n",
    "\n",
    "        with amp.autocast():            \n",
    "            logits, logits2 = model(images)\n",
    "                # logits => tensor([[-1.1621],[-0.7876],[-0.7744],[-0.6548],[-0.8032], ...., [-0.5107], [-0.0616]], device='cuda:0',...)  \n",
    "                # logits2 => tensor([[0.3247]], device='cuda:0',..)\n",
    "                \n",
    "                # targets.max() => tensor(1., device='cuda:0')\n",
    "                # targets.max(1) => torch.return_types.max(values=tensor([1.], device='cuda:0'),indices=tensor([0], device='cuda:0'))\n",
    "                # targets.max(1).values => tensor([1.], device='cuda:0')  \n",
    "                # targets.max(dim=1) => Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim=1. \n",
    "\n",
    "            loss1 = criterion(logits, targets)\n",
    "            loss2 = criterion(logits2, targets.max(1).values)\n",
    "                # loss1 => tensor(0.7388, device='cuda:0', grad_fn=<DivBackward0>) \n",
    "                # loss2 => tensor(0.7343, device='cuda:0', grad_fn=<DivBackward0>)\n",
    "            loss = (loss1 * lw[0] + loss2 * lw[1]) / sum(lw)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(logits, targets_mix)\n",
    "                loss22 = criterion(logits2, targets_mix.max(1).values)\n",
    "                loss = loss * lam  + (loss11 * lw[0] + loss22 * lw[1]) / sum(lw) * (1 - lam)\n",
    "        train_loss1.append(loss1.item())\n",
    "        train_loss2.append(loss2.item())\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "#         bar.set_description(f'smth:{np.mean(train_loss1[-30:]):.4f} {np.mean(train_loss2[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_loss1 = []\n",
    "    valid_loss2 = []\n",
    "    outputs = []\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            logits, logits2 = model(images)\n",
    "            loss1 = criterion(logits, targets)\n",
    "            loss2 = criterion(logits2, targets.max(1).values)\n",
    "            loss = (loss1 + loss2) / 2.\n",
    "            valid_loss1.append(loss1.item())\n",
    "            valid_loss2.append(loss2.item())\n",
    "            valid_loss.append(loss.item())\n",
    "#             bar.set_description(f'smth:{np.mean(valid_loss1[-30:]):.4f} {np.mean(valid_loss2[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(valid_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:11:55.434135Z",
     "iopub.status.busy": "2022-10-29T08:11:55.433782Z",
     "iopub.status.idle": "2022-10-29T08:11:55.637241Z",
     "shell.execute_reply": "2022-10-29T08:11:55.636298Z",
     "shell.execute_reply.started": "2022-10-29T08:11:55.434105Z"
    }
   },
   "outputs": [],
   "source": [
    "# rcParams['figure.figsize'] = 20, 2\n",
    "# optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "# scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "# lrs = []\n",
    "# for epoch in range(1, n_epochs+1):\n",
    "#     scheduler_cosine.step(epoch-1)\n",
    "#     lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "# plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:12:38.503712Z",
     "iopub.status.busy": "2022-10-29T08:12:38.503102Z",
     "iopub.status.idle": "2022-10-29T08:12:38.522409Z",
     "shell.execute_reply": "2022-10-29T08:12:38.521354Z",
     "shell.execute_reply.started": "2022-10-29T08:12:38.503668Z"
    }
   },
   "outputs": [],
   "source": [
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModelType2(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # if not first run, load previous model\n",
    "    fold_l = 2\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold_l}_best.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)    \n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    from_epoch = 0\n",
    "    metric_best = np.inf\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "#     print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "        if epoch < from_epoch + 1:\n",
    "            print(logs[epoch-1])\n",
    "            continue\n",
    "\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss = valid_func(model, loader_valid)\n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric < metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "#         # Save Last\n",
    "#         if not DEBUG:\n",
    "#             torch.save(\n",
    "#                 {\n",
    "#                     'epoch': epoch,\n",
    "#                     'model_state_dict': model.state_dict(),\n",
    "#                     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#                     'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "#                     'score_best': metric_best,\n",
    "#                 },\n",
    "#                 model_file.replace('_best', '_last')\n",
    "#             )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-29T08:12:42.821672Z",
     "iopub.status.busy": "2022-10-29T08:12:42.821292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 27 08:07:20 2023 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1615/1615 [11:13<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████| 403/403 [01:39<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 27 08:20:13 2023 Fold 2, Epoch 1, lr: 0.0000002, train loss: 0.24960, valid loss: 0.31153, metric: 0.311531.\n",
      "metric_best (inf --> 0.311531). Saving model ...\n",
      "Mon Feb 27 08:20:14 2023 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1615/1615 [10:38<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████| 403/403 [01:39<00:00,  4.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 27 08:32:32 2023 Fold 2, Epoch 2, lr: 0.0000002, train loss: 0.24179, valid loss: 0.31035, metric: 0.310353.\n",
      "metric_best (0.311531 --> 0.310353). Saving model ...\n",
      "Mon Feb 27 08:32:32 2023 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1615/1615 [10:36<00:00,  2.54it/s]\n",
      "100%|█████████████████████████████████████████| 403/403 [01:39<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 27 08:44:48 2023 Fold 2, Epoch 3, lr: 0.0000002, train loss: 0.24481, valid loss: 0.31267, metric: 0.312668.\n",
      "Mon Feb 27 08:44:48 2023 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████                       | 689/1615 [04:35<06:09,  2.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46571/1462196937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# run(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# run(3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# run(4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46571/1299259706.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_46571/2167368739.py\u001b[0m in \u001b[0;36mtrain_func\u001b[0;34m(model, loader_train, optimizer, scaler)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/base_2/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run(0)\n",
    "# run(1)\n",
    "run(2)\n",
    "# run(3)\n",
    "# run(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
