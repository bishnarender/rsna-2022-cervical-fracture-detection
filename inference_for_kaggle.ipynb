{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc0f6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:39:40.706698Z",
     "iopub.status.busy": "2023-04-13T13:39:40.705610Z",
     "iopub.status.idle": "2023-04-13T13:39:40.717397Z",
     "shell.execute_reply": "2023-04-13T13:39:40.716498Z"
    },
    "papermill": {
     "duration": 0.022902,
     "end_time": "2023-04-13T13:39:40.719655",
     "exception": false,
     "start_time": "2023-04-13T13:39:40.696753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path = [\n",
    "#     '../input/nar-rsna-library/segmentation-models.pytorch-0.2.1/segmentation-models.pytorch-0.2.1',    \n",
    "    '../input/narrsna20221npyfiles',\n",
    "    '../input/nar-rsna-library/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3',\n",
    "    '../input/nar-rsna-library/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4',\n",
    "    '../input/nar-rsna-library/pylibjpeg-1.4.0/pylibjpeg-1.4.0',    \n",
    "    '../input/nar-rsna-library/pydicom-2.3.0/pydicom-2.3.0',    \n",
    "    '../input/nar-rsna-library/pytorch-image-models-0.6.12/pytorch-image-models-0.6.12',     \n",
    "] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7cffd",
   "metadata": {
    "papermill": {
     "duration": 0.006408,
     "end_time": "2023-04-13T13:39:40.732196",
     "exception": false,
     "start_time": "2023-04-13T13:39:40.725788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac53cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:39:40.746557Z",
     "iopub.status.busy": "2023-04-13T13:39:40.746273Z",
     "iopub.status.idle": "2023-04-13T13:39:42.844012Z",
     "shell.execute_reply": "2023-04-13T13:39:42.842665Z"
    },
    "papermill": {
     "duration": 2.10876,
     "end_time": "2023-04-13T13:39:42.847424",
     "exception": false,
     "start_time": "2023-04-13T13:39:40.738664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r ../input/nar-rsna-library/pytorch-image-models-0.4.12/pytorch-image-models-0.4.12/timm ./timm4smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f897d4",
   "metadata": {
    "papermill": {
     "duration": 0.006305,
     "end_time": "2023-04-13T13:39:42.861125",
     "exception": false,
     "start_time": "2023-04-13T13:39:42.854820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afdd9e12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:39:42.874502Z",
     "iopub.status.busy": "2023-04-13T13:39:42.874179Z",
     "iopub.status.idle": "2023-04-13T13:40:28.059894Z",
     "shell.execute_reply": "2023-04-13T13:40:28.058685Z"
    },
    "papermill": {
     "duration": 45.195573,
     "end_time": "2023-04-13T13:40:28.062626",
     "exception": false,
     "start_time": "2023-04-13T13:39:42.867053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install ../input/nar-rsna-library/segmentation_models_pytorch-0.2.1-py3-none-any.whl --no-deps\n",
    "!pip -q install ../input/nar-rsna-library/python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7351b3f",
   "metadata": {
    "papermill": {
     "duration": 0.006103,
     "end_time": "2023-04-13T13:40:28.075165",
     "exception": false,
     "start_time": "2023-04-13T13:40:28.069062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4514137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:28.089061Z",
     "iopub.status.busy": "2023-04-13T13:40:28.088735Z",
     "iopub.status.idle": "2023-04-13T13:40:28.093383Z",
     "shell.execute_reply": "2023-04-13T13:40:28.092364Z"
    },
    "papermill": {
     "duration": 0.014407,
     "end_time": "2023-04-13T13:40:28.095705",
     "exception": false,
     "start_time": "2023-04-13T13:40:28.081298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980bb19b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:28.109920Z",
     "iopub.status.busy": "2023-04-13T13:40:28.109130Z",
     "iopub.status.idle": "2023-04-13T13:40:35.972711Z",
     "shell.execute_reply": "2023-04-13T13:40:35.971607Z"
    },
    "papermill": {
     "duration": 7.87391,
     "end_time": "2023-04-13T13:40:35.975696",
     "exception": false,
     "start_time": "2023-04-13T13:40:28.101786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "import gc, ast, cv2, time, timm, timm4smp, pickle, random, pylibjpeg, pydicom\n",
    "import argparse\n",
    "import warnings\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caece9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:35.990237Z",
     "iopub.status.busy": "2023-04-13T13:40:35.989923Z",
     "iopub.status.idle": "2023-04-13T13:40:35.995176Z",
     "shell.execute_reply": "2023-04-13T13:40:35.994140Z"
    },
    "papermill": {
     "duration": 0.015126,
     "end_time": "2023-04-13T13:40:35.997384",
     "exception": false,
     "start_time": "2023-04-13T13:40:35.982258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '../input/rsna-2022-cervical-spine-fracture-detection'\n",
    "image_size_seg = (128, 128, 128)\n",
    "msk_size = image_size_seg[0]\n",
    "image_size_cls = 224\n",
    "n_slice_per_c = 15\n",
    "n_ch = 5\n",
    "\n",
    "batch_size_seg = 1\n",
    "num_workers = 2\n",
    "model_dir_seg = '../input/nar-rsna-2022-models/kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c59c4b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:36.012292Z",
     "iopub.status.busy": "2023-04-13T13:40:36.011790Z",
     "iopub.status.idle": "2023-04-13T13:40:36.049585Z",
     "shell.execute_reply": "2023-04-13T13:40:36.048478Z"
    },
    "papermill": {
     "duration": 0.047811,
     "end_time": "2023-04-13T13:40:36.051921",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.004110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>image_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>../input/rsna-2022-cervical-spine-fracture-det...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            StudyInstanceUID  \\\n",
       "0  1.2.826.0.1.3680043.22327   \n",
       "1  1.2.826.0.1.3680043.25399   \n",
       "2   1.2.826.0.1.3680043.5876   \n",
       "\n",
       "                                        image_folder  \n",
       "0  ../input/rsna-2022-cervical-spine-fracture-det...  \n",
       "1  ../input/rsna-2022-cervical-spine-fracture-det...  \n",
       "2  ../input/rsna-2022-cervical-spine-fracture-det...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "    df = pd.DataFrame({\n",
    "        'StudyInstanceUID': df['StudyInstanceUID'].unique().tolist()\n",
    "    })\n",
    "    df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(data_dir, 'train_images', x))\n",
    "else:\n",
    "    df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "    if df.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n",
    "        # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n",
    "        df = pd.DataFrame({\"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_C1'],\n",
    "                               \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n",
    "                               \"prediction_type\": [\"C1\", \"C1\", \"C1\"]}\n",
    "                         )\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'StudyInstanceUID': df['StudyInstanceUID'].unique().tolist()\n",
    "    })\n",
    "    df['image_folder'] = df['StudyInstanceUID'].apply(lambda x: os.path.join(data_dir, 'test_images', x))\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b794f1ca",
   "metadata": {
    "papermill": {
     "duration": 0.007035,
     "end_time": "2023-04-13T13:40:36.065761",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.058726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5200f3b",
   "metadata": {
    "papermill": {
     "duration": 0.00605,
     "end_time": "2023-04-13T13:40:36.078125",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.072075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93558678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:36.092220Z",
     "iopub.status.busy": "2023-04-13T13:40:36.091919Z",
     "iopub.status.idle": "2023-04-13T13:40:36.104242Z",
     "shell.execute_reply": "2023-04-13T13:40:36.103327Z"
    },
    "papermill": {
     "duration": 0.021974,
     "end_time": "2023-04-13T13:40:36.106400",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.084426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (image_size_seg[0], image_size_seg[1]), interpolation = cv2.INTER_AREA)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dicom_line_par(path):\n",
    "    t_paths = sorted(glob(os.path.join(path, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "    n_scans = len(t_paths)\n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., image_size_seg[2])).round().astype(int)\n",
    "    t_paths = [t_paths[i] for i in indices]\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, 0) \n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "    return images, indices\n",
    "\n",
    "\n",
    "class SegTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        image, index = load_dicom_line_par(row.image_folder)\n",
    "        if image.ndim < 4:\n",
    "            image = np.expand_dims(image, axis=0).repeat(3, axis=0)\n",
    "        image = image / 255.\n",
    "        return torch.tensor(image).float(), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8f8c7",
   "metadata": {
    "papermill": {
     "duration": 0.006327,
     "end_time": "2023-04-13T13:40:36.118987",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.112660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6f8e117",
   "metadata": {
    "papermill": {
     "duration": 0.006417,
     "end_time": "2023-04-13T13:40:36.131785",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.125368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fec9c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:36.146217Z",
     "iopub.status.busy": "2023-04-13T13:40:36.145941Z",
     "iopub.status.idle": "2023-04-13T13:40:36.191486Z",
     "shell.execute_reply": "2023-04-13T13:40:36.190575Z"
    },
    "papermill": {
     "duration": 0.055587,
     "end_time": "2023-04-13T13:40:36.193676",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.138089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from conv2d_same import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "def convert_3d(module):\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )        \n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig            \n",
    "    elif isinstance(module, Conv2dSame):\n",
    "        module_output = Conv3dSame(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module( name, convert_3d(child) )\n",
    "    del module\n",
    "    return module_output\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "        self.encoder = timm4smp.create_model( \n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [160, 64, 48, 24, 16]   \n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "                attention_type='scse',\n",
    "            )\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    def forward(self,x):\n",
    "        enc_features = self.encoder(x)[:n_blocks]\n",
    "        f, d = enc_features[0].shape[0], enc_features[0].device\n",
    "        a = [24,48,64,160]\n",
    "        b = [63,31,15,7]\n",
    "        enc_features = [torch.cat((feat, torch.ones((f,a[i],1,b[i],b[i]), device=d).float()), dim=2) for i, feat in enumerate(enc_features)]\n",
    "        enc_features = [torch.cat((feat, torch.ones((f,a[i],b[i]+1,1,b[i]), device=d).float()), dim=3) for i, feat in enumerate(enc_features)]      \n",
    "        enc_features = [torch.cat((feat, torch.ones((f,a[i],b[i]+1,b[i]+1,1), device=d).float()), dim=4) for i, feat in enumerate(enc_features)]           \n",
    "        global_features = [0] + enc_features\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "    \n",
    "class TimmModel(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModel, self).__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )        \n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256),\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  \n",
    "        bs = x.shape[0]        \n",
    "        x = x.view(bs * n_slice_per_c, in_chans, image_size, image_size)        \n",
    "        feat = self.encoder(x)        \n",
    "        feat = feat.view(bs, n_slice_per_c, -1)        \n",
    "        feat, _ = self.lstm(feat) \n",
    "        feat = feat.contiguous().view(bs * n_slice_per_c, -1)    \n",
    "        feat = self.head(feat)\n",
    "        feat = feat.view(bs, n_slice_per_c).contiguous()\n",
    "        return feat    \n",
    "    \n",
    "class TimmModelType2(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModelType2, self).__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256), \n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.InstanceNorm1d(256), \n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c * 7, in_chans, image_size, image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c * 7, -1)\n",
    "        feat1, _ = self.lstm(feat)\n",
    "        feat1 = feat1.contiguous().view(bs * n_slice_per_c * 7, 512)\n",
    "        feat2, _ = self.lstm2(feat)\n",
    "        return self.head(feat1), self.head2(feat2[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9fe9e2",
   "metadata": {
    "papermill": {
     "duration": 0.00633,
     "end_time": "2023-04-13T13:40:36.206639",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.200309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c6f449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:36.220675Z",
     "iopub.status.busy": "2023-04-13T13:40:36.220379Z",
     "iopub.status.idle": "2023-04-13T13:40:48.346640Z",
     "shell.execute_reply": "2023-04-13T13:40:48.345615Z"
    },
    "papermill": {
     "duration": 12.135858,
     "end_time": "2023-04-13T13:40:48.349095",
     "exception": false,
     "start_time": "2023-04-13T13:40:36.213237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_type = 'timm3d_effv2_unet4b_128_128_128_dsv2_flip12_shift333p7_gd1p5_bs4_lr3e4_20x50ep'\n",
    "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
    "models_seg = []\n",
    "\n",
    "n_blocks = 4\n",
    "for fold in range(5):\n",
    "    model = TimmSegModel(backbone, pretrained=False)\n",
    "    model = convert_3d(model)\n",
    "    model = model.to(device)\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold}_best.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    models_seg.append(model)\n",
    "\n",
    "len(models_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f7375",
   "metadata": {
    "papermill": {
     "duration": 0.006308,
     "end_time": "2023-04-13T13:40:48.362272",
     "exception": false,
     "start_time": "2023-04-13T13:40:48.355964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e55c952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:48.376363Z",
     "iopub.status.busy": "2023-04-13T13:40:48.376053Z",
     "iopub.status.idle": "2023-04-13T13:40:56.324959Z",
     "shell.execute_reply": "2023-04-13T13:40:56.323791Z"
    },
    "papermill": {
     "duration": 7.958588,
     "end_time": "2023-04-13T13:40:56.327217",
     "exception": false,
     "start_time": "2023-04-13T13:40:48.368629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_type = '0920_1bonev2_effv2s_224_15_6ch_augv2_mixupp5_drl3_rov1p2_bs8_lr23e5_eta23e6_50ep'\n",
    "backbone = 'tf_efficientnetv2_s_in21ft1k'\n",
    "\n",
    "image_size = 224\n",
    "in_chans = 6\n",
    "models_cls1 = []\n",
    "out_dim = 1\n",
    "drop_rate = 0.\n",
    "drop_rate_last = 0. \n",
    "drop_path_rate = 0.\n",
    "for fold in range(5):\n",
    "    model = TimmModel(backbone, pretrained=False)\n",
    "    model = model.to(device)\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold}_last.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    models_cls1.append(model)\n",
    "\n",
    "len(models_cls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41f6c772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:40:56.343267Z",
     "iopub.status.busy": "2023-04-13T13:40:56.342282Z",
     "iopub.status.idle": "2023-04-13T13:41:01.471797Z",
     "shell.execute_reply": "2023-04-13T13:41:01.470604Z"
    },
    "papermill": {
     "duration": 5.140267,
     "end_time": "2023-04-13T13:41:01.474520",
     "exception": false,
     "start_time": "2023-04-13T13:40:56.334253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_type = '0920_2d_lstmv22headv2_convnn_224_15_6ch_8flip_augv2_drl3_rov1p2_rov3p2_bs4_lr6e5_eta6e6_lw151_50ep'\n",
    "backbone = 'convnext_nano'\n",
    "in_chans = 6\n",
    "models_cls2 = []\n",
    "\n",
    "for fold in range(5):\n",
    "    model = TimmModelType2(backbone, pretrained=False)\n",
    "    model = model.to(device)\n",
    "    load_model_file = os.path.join(model_dir_seg, f'{kernel_type}_fold{fold}_last.pth')\n",
    "    sd = torch.load(load_model_file)\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    model.load_state_dict(sd, strict=True)\n",
    "    model.eval()\n",
    "    models_cls2.append(model)\n",
    "\n",
    "len(models_cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca26e6f",
   "metadata": {
    "papermill": {
     "duration": 0.006984,
     "end_time": "2023-04-13T13:41:01.488980",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.481996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2caeb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:41:01.503868Z",
     "iopub.status.busy": "2023-04-13T13:41:01.503527Z",
     "iopub.status.idle": "2023-04-13T13:41:01.523585Z",
     "shell.execute_reply": "2023-04-13T13:41:01.522495Z"
    },
    "papermill": {
     "duration": 0.030249,
     "end_time": "2023-04-13T13:41:01.525848",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.495599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_bone(msk, cid, t_paths, cropped_images, index, inst_id):\n",
    "    sema.acquire() #  threading topic\n",
    "    n_scans = len(t_paths)\n",
    "    bone = []\n",
    "    try:\n",
    "        msk_b = msk[cid] > 0.2\n",
    "        msk_c = msk[cid] > 0.02\n",
    "        y = np.where(msk_b.sum(0).sum(0) > 0)[0]\n",
    "        x = np.where(msk_b.sum(0).sum(1) > 0)[0]        \n",
    "        z = np.where(msk_b.sum(1).sum(1) > 0)[0]\n",
    "        if len(x) == 0 or len(y) == 0 or len(z) == 0:\n",
    "            y = np.where(msk_c.sum(0).sum(0) > 0)[0]            \n",
    "            x = np.where(msk_c.sum(0).sum(1) > 0)[0]\n",
    "            z = np.where(msk_c.sum(1).sum(1) > 0)[0]                        \n",
    "        y1, y2 = max(0, y[0]), min(msk.shape[2]-1, y[-1])        \n",
    "        x1, x2 = max(0, x[0]), min(msk.shape[3]-1, x[-1])\n",
    "        z1, z2 = max(2, z[0]), min(msk.shape[1]-3, z[-1])\n",
    "#         zz1, zz2 = int(z1 / msk_size * n_scans), int(z2 / msk_size * n_scans)\n",
    "        inds_ = np.linspace(z1 ,z2 ,n_slice_per_c).astype(int)        \n",
    "#         inds = np.linspace(zz1 ,zz2 ,n_slice_per_c).astype(int)        \n",
    "        for ind_ in inds_:        \n",
    "#         for sid, (ind, ind_) in enumerate(zip(inds, inds_)):            \n",
    "            k = index[0][ind_]            \n",
    "            images = []\n",
    "            for i in [-2,-1,0,1,2]: \n",
    "                try:\n",
    "                    dicom = pydicom.read_file(t_paths[k+i])                        \n",
    "                    images.append(dicom.pixel_array)\n",
    "                except:\n",
    "                    images.append(np.ones((512, 512)))            \n",
    "            data = np.stack(images, -1)\n",
    "            data = data - np.min(data)\n",
    "            data = data / (np.max(data) + 1e-4)\n",
    "            data = (data * 255).astype(np.uint8)  \n",
    "            \n",
    "            xx1 = int(x1 / msk_size * data.shape[0])\n",
    "            xx2 = int(x2 / msk_size * data.shape[0])\n",
    "            yy1 = int(y1 / msk_size * data.shape[1])\n",
    "            yy2 = int(y2 / msk_size * data.shape[1])\n",
    "            data = data[xx1:xx2, yy1:yy2]\n",
    "            data = np.stack([cv2.resize(data[:, :, i], (image_size_cls, image_size_cls), interpolation = cv2.INTER_LINEAR) for i in range(n_ch)], -1) \n",
    "            msk_this = msk[cid, ind_, :, :] \n",
    "            msk_this = msk_this[x1:x2, y1:y2]                                             \n",
    "            msk_this = (msk_this * 255).astype(np.uint8)\n",
    "            msk_this = cv2.resize(msk_this, (image_size_cls, image_size_cls), interpolation = cv2.INTER_LINEAR)            \n",
    "            data = np.concatenate([data, msk_this[:, :, np.newaxis]], -1) \n",
    "            data = (data / 255.).astype(np.float32)\n",
    "            bone.append(torch.tensor(data))                \n",
    "    except:\n",
    "        for sid in range(n_slice_per_c):\n",
    "            bone.append(torch.ones((image_size_cls, image_size_cls, n_ch+1)).float())    \n",
    "    cropped_images[cid] = torch.stack(bone, 0)\n",
    "    sema.release() #  threading topic\n",
    "    \n",
    "def load_cropped_images(msk, image_folder, index, inst_id, n_ch=n_ch):\n",
    "    t_paths = sorted(glob(os.path.join(image_folder, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))    \n",
    "    for cid in range(7): \n",
    "        threads[cid] = threading.Thread(target=load_bone, args=(msk, cid, t_paths, cropped_images, index, inst_id))\n",
    "        threads[cid].start()\n",
    "    for cid in range(7):\n",
    "        threads[cid].join()        \n",
    "    return torch.cat(cropped_images, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d61148",
   "metadata": {
    "papermill": {
     "duration": 0.006326,
     "end_time": "2023-04-13T13:41:01.538840",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.532514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3239f161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:41:01.553801Z",
     "iopub.status.busy": "2023-04-13T13:41:01.553129Z",
     "iopub.status.idle": "2023-04-13T13:41:01.560207Z",
     "shell.execute_reply": "2023-04-13T13:41:01.558574Z"
    },
    "papermill": {
     "duration": 0.016746,
     "end_time": "2023-04-13T13:41:01.562380",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.545634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sema = threading.Semaphore(value=2) # value => setting number of threads\n",
    "dataset_seg = SegTestDataset(df)\n",
    "loader_seg = torch.utils.data.DataLoader(dataset_seg, batch_size=batch_size_seg, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9370bf4",
   "metadata": {
    "papermill": {
     "duration": 0.006414,
     "end_time": "2023-04-13T13:41:01.575316",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.568902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e9d1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:41:01.589643Z",
     "iopub.status.busy": "2023-04-13T13:41:01.589312Z",
     "iopub.status.idle": "2023-04-13T13:41:33.031813Z",
     "shell.execute_reply": "2023-04-13T13:41:33.029914Z"
    },
    "papermill": {
     "duration": 31.4523,
     "end_time": "2023-04-13T13:41:33.034167",
     "exception": false,
     "start_time": "2023-04-13T13:41:01.581867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:31<00:00, 10.47s/it]\n"
     ]
    }
   ],
   "source": [
    "outputs1 = []\n",
    "outputs2 = []\n",
    "\n",
    "bar = tqdm(loader_seg)\n",
    "with torch.no_grad():\n",
    "    for batch_id, (images, indices) in enumerate(bar):\n",
    "        indices = indices.numpy()\n",
    "        images = images.cuda()\n",
    "        # SEG\n",
    "        pred_masks = []\n",
    "        for model in models_seg:\n",
    "            pmask = model(images)\n",
    "            pmask = pmask.sigmoid()\n",
    "            pred_masks.append(pmask)\n",
    "        pred_masks = torch.stack(pred_masks, 0).mean(0).cpu().numpy()                    \n",
    "\n",
    "        # Build cls input\n",
    "        cls_inp = []\n",
    "        threads = [None] * 7\n",
    "        cropped_images = [None] * 7\n",
    "\n",
    "        for i in range(pred_masks.shape[0]):\n",
    "            row = df.iloc[batch_id*batch_size_seg+i]\n",
    "            cropped_images = load_cropped_images(pred_masks[i], row.image_folder, indices, row.StudyInstanceUID)\n",
    "#             cropped_images = cropped_images[:105,:,:,:] # torch.Size([119, 224, 224, 6]) reduces to torch.Size([105, 224, 224, 6])                \n",
    "            cls_inp.append(cropped_images.permute(0, 3, 1, 2))       \n",
    "        cls_inp = torch.stack(cls_inp, 0).to(device)  # (1, 105, 6, 224, 224)\n",
    "\n",
    "        pred_cls1, pred_cls2 = [], []\n",
    "        # CLS 2\n",
    "        for _, model in enumerate(models_cls2):\n",
    "            logits, logits2 = model(cls_inp)       \n",
    "            pred_cls1.append(logits.sigmoid().view(-1, 7, n_slice_per_c))\n",
    "            pred_cls2.append(logits2.sigmoid())                            \n",
    "\n",
    "        # CLS 1\n",
    "        cls_inp = cls_inp.view(7, 15, 6, image_size_cls, image_size_cls).contiguous()\n",
    "        for _, model in enumerate(models_cls1):\n",
    "            logits = model(cls_inp)\n",
    "            pred_cls1.append(logits.sigmoid().view(-1, 7, n_slice_per_c)) \n",
    "\n",
    "        pred_cls1 = torch.stack(pred_cls1, 0).mean(0)\n",
    "        pred_cls2 = torch.stack(pred_cls2, 0).mean(0)\n",
    "        outputs1.append(pred_cls1.cpu())\n",
    "        outputs2.append(pred_cls2.cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c7339c",
   "metadata": {
    "papermill": {
     "duration": 0.006841,
     "end_time": "2023-04-13T13:41:33.048225",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.041384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d28c08",
   "metadata": {
    "papermill": {
     "duration": 0.007178,
     "end_time": "2023-04-13T13:41:33.062456",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.055278",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446eec8",
   "metadata": {
    "papermill": {
     "duration": 0.006863,
     "end_time": "2023-04-13T13:41:33.076431",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.069568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfcdb6f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:41:33.092344Z",
     "iopub.status.busy": "2023-04-13T13:41:33.091429Z",
     "iopub.status.idle": "2023-04-13T13:41:33.106097Z",
     "shell.execute_reply": "2023-04-13T13:41:33.105001Z"
    },
    "papermill": {
     "duration": 0.024943,
     "end_time": "2023-04-13T13:41:33.108263",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.083320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "outputs1 = torch.cat(outputs1)  \n",
    "outputs2 = torch.cat(outputs2)\n",
    "PRED1 = (outputs1.mean(-1)).clamp(0.0001, 0.9999)\n",
    "PRED2 = (outputs2.view(-1)).clamp(0.0001, 0.9999)    \n",
    "row_ids = []\n",
    "for _, row in df.iterrows():\n",
    "    for i in range(7):\n",
    "        row_ids.append(row.StudyInstanceUID + f'_C{i+1}')\n",
    "    row_ids.append(row.StudyInstanceUID + '_patient_overall')\n",
    "df_sub = pd.DataFrame({\n",
    "    'row_id': row_ids,\n",
    "    'fractured': torch.cat([PRED1, PRED2.unsqueeze(1)], 1).view(-1),\n",
    "})\n",
    "df_sub.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f3c973e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-13T13:41:33.123405Z",
     "iopub.status.busy": "2023-04-13T13:41:33.123089Z",
     "iopub.status.idle": "2023-04-13T13:41:33.134350Z",
     "shell.execute_reply": "2023-04-13T13:41:33.133248Z"
    },
    "papermill": {
     "duration": 0.02134,
     "end_time": "2023-04-13T13:41:33.136525",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.115185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>fractured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C1</td>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C2</td>\n",
       "      <td>0.014304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C3</td>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C4</td>\n",
       "      <td>0.003778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C5</td>\n",
       "      <td>0.004552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C6</td>\n",
       "      <td>0.010180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C7</td>\n",
       "      <td>0.045141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_patient_overall</td>\n",
       "      <td>0.461741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C1</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C2</td>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C3</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C4</td>\n",
       "      <td>0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C5</td>\n",
       "      <td>0.003658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C6</td>\n",
       "      <td>0.005277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C7</td>\n",
       "      <td>0.012654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_patient_overall</td>\n",
       "      <td>0.089544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C1</td>\n",
       "      <td>0.011744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C2</td>\n",
       "      <td>0.043882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C3</td>\n",
       "      <td>0.003417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C4</td>\n",
       "      <td>0.003471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C5</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C6</td>\n",
       "      <td>0.004640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_C7</td>\n",
       "      <td>0.048108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_patient_overall</td>\n",
       "      <td>0.124021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       row_id  fractured\n",
       "0                1.2.826.0.1.3680043.22327_C1   0.004043\n",
       "1                1.2.826.0.1.3680043.22327_C2   0.014304\n",
       "2                1.2.826.0.1.3680043.22327_C3   0.003280\n",
       "3                1.2.826.0.1.3680043.22327_C4   0.003778\n",
       "4                1.2.826.0.1.3680043.22327_C5   0.004552\n",
       "5                1.2.826.0.1.3680043.22327_C6   0.010180\n",
       "6                1.2.826.0.1.3680043.22327_C7   0.045141\n",
       "7   1.2.826.0.1.3680043.22327_patient_overall   0.461741\n",
       "8                1.2.826.0.1.3680043.25399_C1   0.080464\n",
       "9                1.2.826.0.1.3680043.25399_C2   0.003079\n",
       "10               1.2.826.0.1.3680043.25399_C3   0.003400\n",
       "11               1.2.826.0.1.3680043.25399_C4   0.004297\n",
       "12               1.2.826.0.1.3680043.25399_C5   0.003658\n",
       "13               1.2.826.0.1.3680043.25399_C6   0.005277\n",
       "14               1.2.826.0.1.3680043.25399_C7   0.012654\n",
       "15  1.2.826.0.1.3680043.25399_patient_overall   0.089544\n",
       "16                1.2.826.0.1.3680043.5876_C1   0.011744\n",
       "17                1.2.826.0.1.3680043.5876_C2   0.043882\n",
       "18                1.2.826.0.1.3680043.5876_C3   0.003417\n",
       "19                1.2.826.0.1.3680043.5876_C4   0.003471\n",
       "20                1.2.826.0.1.3680043.5876_C5   0.003718\n",
       "21                1.2.826.0.1.3680043.5876_C6   0.004640\n",
       "22                1.2.826.0.1.3680043.5876_C7   0.048108\n",
       "23   1.2.826.0.1.3680043.5876_patient_overall   0.124021"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d0d2a",
   "metadata": {
    "papermill": {
     "duration": 0.007481,
     "end_time": "2023-04-13T13:41:33.151591",
     "exception": false,
     "start_time": "2023-04-13T13:41:33.144110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.683207,
   "end_time": "2023-04-13T13:41:35.184159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-13T13:39:31.500952",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
